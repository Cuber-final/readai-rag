{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import (\n",
    "    UnstructuredEPubLoader,\n",
    "    UnstructuredMarkdownLoader,\n",
    ")\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "from readai.components.loaders import MarkdownReader\n",
    "\n",
    "# 加载.env文件\n",
    "load_dotenv()\n",
    "\n",
    "# 获取项目根目录路径\n",
    "project_root = Path(os.getenv(\"PROJECT_ROOT\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = project_root / \"readai/tests/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用epubloader，效果不太理想"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点数量: 1795\n"
     ]
    }
   ],
   "source": [
    "# 第一步：使用 UnstructuredEPubLoader 加载 EPUB 文档\n",
    "# 读取PROJECT_ROOT\n",
    "\n",
    "book_name = \"非暴力沟通.epub\"\n",
    "book_path = test_data_path / book_name\n",
    "loader = UnstructuredEPubLoader(book_path, mode=\"elements\", strategy=\"fast\")\n",
    "documents = loader.load()\n",
    "print(f\"节点数量: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epub转markdown\n",
    "- 优点是处理起来更好更方便，可以在load之前还进一步对文本清洗，过滤多余的空行，让内容更接近原本的段落，章节形式\n",
    "- 使用UnstructuredMarkdownLoader读取，但会存在很多用不上的metadata属性，所以需要删除过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点数量: 41\n"
     ]
    }
   ],
   "source": [
    "book_name = \"comunication_cleaned.md\"\n",
    "book_path = test_data_path / book_name\n",
    "# 使用unstructured的markdownloader加载\n",
    "loader = UnstructuredMarkdownLoader(book_path, mode=\"elements\")\n",
    "documents = loader.load()\n",
    "# 查看节点数量\n",
    "print(f\"节点数量: {len(documents)}\")\n",
    "# 遍历documents,重构metadata，只保留category，filename这两个属性\n",
    "for doc in documents:\n",
    "    category = doc.metadata[\"category\"]\n",
    "    filename = doc.metadata[\"filename\"]\n",
    "    doc.metadata = {\n",
    "        \"category\": category,\n",
    "        \"filename\": filename,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LLM sees this:\n",
      " Metadata: category=>NarrativeText::filename=>comunication_cleaned.md\n",
      "-----\n",
      "Content: 马歇尔·卢森堡博士发现了一种沟通方式，依照它来谈话和聆听，能使人们情意相通，和谐相处，这就是“非暴力沟通”。 做为一个遵纪守法的好人，也许我们从来没有把谈话和“暴力”扯上关系。不过如果稍微留意一下现实生活中的谈话方式，并且用心体会各种谈话方式给我们的不同感受，我们一定会发现，有些话确实伤人！言语上的指责、嘲讽、否定、说教以及任意打断、拒不回应、随意出口的评价和结论给我们带来的情感和精神上的创伤甚至比肉体的伤害更加令人痛苦。这些无心或有意的语言暴力让人与人变得冷漠、隔膜、敌视。 非暴力沟通能够： ● 疗愈内心深处的隐秘伤痛； ● 超越个人心智和情感的局限性； ● 突破那些引发愤怒、沮丧、焦虑等负面情绪的思维方式； ● 用不带伤害的方式化解人际间的冲突； ● 学会建立和谐的生命体验。 图书在版编目(CIP)数据 非暴力沟通／（美）马歇尔·卢森堡（Marshall B.Rosenberg）著；刘轶译.-2版（修订本）-北京：华夏出版社有限公司，2021.5 书名原文：Nonviolent Communication ISBN 978-7-5222-0051-4 Ⅰ.①非⋯Ⅱ.①马⋯②刘⋯Ⅲ.①心理交往-通俗读物Ⅳ.①C912.11-49 中国版本图书馆CIP数据核字（2021）第006542号 Translated from the book Nonviolent Communication:A Language of Life 3rd Edition,ISBN 13/10:9781892005281/189200528X by Marshall B.Rosenberg. Copyright ? Fall 2015 Puddle Dancer Press,published by Puddle Dancer Press. All rights reserved. Used with permission. For further information about Nonviolent Communication(TM) please visit the Center for Nonviolent Communication on the Web at:www.cnvc.org. 版权所有翻印必究 北京市版权局著作权合同登记号：图字01-2016-2253号 非暴力沟通 著 者 [美]马歇尔·卢森堡 译 者 刘 轶 责任编辑 朱 悦 责任印制 刘 洋 出版发行 华夏出版社 经 销 新华书店 印 刷 三河市少明印务有限公司 装 订 三河市少明印务有限公司 版 次 2021年5月北京第2版 2021年5月北京第1次印刷 开 本 720x1030 1/16开 印 张 16 彩 页 6页 字 数 190千字 定 价 59.80元 华夏出版社有限公司 地址：北京市东直门外香河园北里4号 邮编：100028 网址：www.hxph.com.cn 电话：(010)64663331(转) 若发现本版图书有印装质量问题，请与我社营销中心联系调换． 有关非暴力沟通的更多信息，请联系非暴力沟通中心，地址如下 Center for Nonviolent Communication (CNVC) 9301 Indian School Rd., NE, Suite 204Albuquerque NM 87112-2861 USA Ph: 505-244-4041 US Only: 800-255-7696 Fax: 505-247-0414 Email: cnvc@CNVC.org Website: www.CNVC.org 目录\n",
      "The Embedding model sees this: \n",
      " Metadata: category=>NarrativeText::filename=>comunication_cleaned.md\n",
      "-----\n",
      "Content: 马歇尔·卢森堡博士发现了一种沟通方式，依照它来谈话和聆听，能使人们情意相通，和谐相处，这就是“非暴力沟通”。 做为一个遵纪守法的好人，也许我们从来没有把谈话和“暴力”扯上关系。不过如果稍微留意一下现实生活中的谈话方式，并且用心体会各种谈话方式给我们的不同感受，我们一定会发现，有些话确实伤人！言语上的指责、嘲讽、否定、说教以及任意打断、拒不回应、随意出口的评价和结论给我们带来的情感和精神上的创伤甚至比肉体的伤害更加令人痛苦。这些无心或有意的语言暴力让人与人变得冷漠、隔膜、敌视。 非暴力沟通能够： ● 疗愈内心深处的隐秘伤痛； ● 超越个人心智和情感的局限性； ● 突破那些引发愤怒、沮丧、焦虑等负面情绪的思维方式； ● 用不带伤害的方式化解人际间的冲突； ● 学会建立和谐的生命体验。 图书在版编目(CIP)数据 非暴力沟通／（美）马歇尔·卢森堡（Marshall B.Rosenberg）著；刘轶译.-2版（修订本）-北京：华夏出版社有限公司，2021.5 书名原文：Nonviolent Communication ISBN 978-7-5222-0051-4 Ⅰ.①非⋯Ⅱ.①马⋯②刘⋯Ⅲ.①心理交往-通俗读物Ⅳ.①C912.11-49 中国版本图书馆CIP数据核字（2021）第006542号 Translated from the book Nonviolent Communication:A Language of Life 3rd Edition,ISBN 13/10:9781892005281/189200528X by Marshall B.Rosenberg. Copyright ? Fall 2015 Puddle Dancer Press,published by Puddle Dancer Press. All rights reserved. Used with permission. For further information about Nonviolent Communication(TM) please visit the Center for Nonviolent Communication on the Web at:www.cnvc.org. 版权所有翻印必究 北京市版权局著作权合同登记号：图字01-2016-2253号 非暴力沟通 著 者 [美]马歇尔·卢森堡 译 者 刘 轶 责任编辑 朱 悦 责任印制 刘 洋 出版发行 华夏出版社 经 销 新华书店 印 刷 三河市少明印务有限公司 装 订 三河市少明印务有限公司 版 次 2021年5月北京第2版 2021年5月北京第1次印刷 开 本 720x1030 1/16开 印 张 16 彩 页 6页 字 数 190千字 定 价 59.80元 华夏出版社有限公司 地址：北京市东直门外香河园北里4号 邮编：100028 网址：www.hxph.com.cn 电话：(010)64663331(转) 若发现本版图书有印装质量问题，请与我社营销中心联系调换． 有关非暴力沟通的更多信息，请联系非暴力沟通中心，地址如下 Center for Nonviolent Communication (CNVC) 9301 Indian School Rd., NE, Suite 204Albuquerque NM 87112-2861 USA Ph: 505-244-4041 US Only: 800-255-7696 Fax: 505-247-0414 Email: cnvc@CNVC.org Website: www.CNVC.org 目录\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "llamindex_docs = [\n",
    "    Document(\n",
    "        text=doc.page_content,\n",
    "        metadata=doc.metadata,\n",
    "        metadata_seperator=\"::\",\n",
    "        metadata_template=\"{key}=>{value}\",\n",
    "        text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n",
    "    )\n",
    "    for doc in documents\n",
    "]\n",
    "print(\n",
    "    \"The LLM sees this:\\n\",\n",
    "    llamindex_docs[0].get_content(metadata_mode=MetadataMode.LLM),\n",
    ")\n",
    "print(\n",
    "    \"The Embedding model sees this: \\n\",\n",
    "    llamindex_docs[0].get_content(metadata_mode=MetadataMode.EMBED),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(llamindex_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 查看node有哪些属性,按照json格式输出\n",
    "print(len(llamindex_docs))\n",
    "# processed_nodes节点输出全部看看,保存内容到json文件中\n",
    "with open(\"llamindex_docs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for node in llamindex_docs:\n",
    "        # 数据转json\n",
    "        json_data = json.dumps(node.to_dict(), ensure_ascii=False, indent=2)\n",
    "        f.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用LLamaindex的MarkdownReader加载,效果不如unstructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用LLamaindex的MarkdownReader加载\n",
    "book_name = \"comunication_cleaned.md\"\n",
    "book_path = test_data_path / book_name\n",
    "reader = MarkdownReader()\n",
    "documents = reader.load_data(book_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "马歇尔·卢森堡博士发现了一种沟通方式，依照它来谈话和聆听，能使人们情意相通，和谐相处，这就是“非暴力沟通”。\n",
      "做为一个遵纪守法的好人，也许我们从来没有把谈话和“暴力”扯上关系。不过如果稍微留意一下现实生活中的谈话方式，并且用心体会各种谈话方式给我们的不同感受，我们一定会发现，有些话确实伤人！言语上的指责、嘲讽、否定、说教以及任意打断、拒不回应、随意出口的评价和结论给我们带来的情感和精神上的创伤甚至比肉体的伤害更加令人痛苦。这些无心或有意的语言暴力让人与人变得冷漠、隔膜、敌视。\n",
      "非暴力沟通能够：\n",
      "● 疗愈内心深处的隐秘伤痛；\n",
      "● 超越个人心智和情感的局限性；\n",
      "● 突破那些引发愤怒、沮丧、焦虑等负面情绪的思维方式；\n",
      "● 用不带伤害的方式化解人际间的冲突；\n",
      "● 学会建立和谐的生命体验。\n",
      "图书在版编目(CIP)数据\n",
      "非暴力沟通／（美）马歇尔·卢森堡（Marshall B.Rosenberg）著；刘轶译.-2版（修订本）-北京：华夏出版社有限公司，2021.5\n",
      "书名原文：Nonviolent Communication\n",
      "ISBN 978-7-5222-0051-4\n",
      "Ⅰ.①非⋯Ⅱ.①马⋯②刘⋯Ⅲ.①心理交往-通俗读物Ⅳ.①C912.11-49\n",
      "中国版本图书馆CIP数据核字（2021）第006542号\n",
      "Translated from the book Nonviolent Communication:A Language of Life 3rd Edition,ISBN 13/10:9781892005281/189200528X by Marshall B.Rosenberg. Copyright ? Fall 2015 Puddle Dancer Press,published by Puddle Dancer Press.\n",
      "All rights reserved.\n",
      "Used with permission.\n",
      "For further information about Nonviolent Communication(TM) please visit the Center for Nonviolent Communication on the Web at:www.cnvc.org.\n",
      "版权所有翻印必究\n",
      "北京市版权局著作权合同登记号：图字01-2016-2253号\n",
      "非暴力沟通\n",
      "著　　者　[美]马歇尔·卢森堡\n",
      "译　　者　刘　轶\n",
      "责任编辑　朱　悦\n",
      "责任印制　刘　洋\n",
      "出版发行　华夏出版社\n",
      "经　　销　新华书店\n",
      "印　　刷　三河市少明印务有限公司\n",
      "装　　订　三河市少明印务有限公司\n",
      "版　　次　2021年5月北京第2版　2021年5月北京第1次印刷\n",
      "开　　本　720x1030　1/16开\n",
      "印　　张　16\n",
      "彩　　页　6页\n",
      "字　　数　190千字\n",
      "定　　价　59.80元\n",
      "华夏出版社有限公司\n",
      "地址：北京市东直门外香河园北里4号\n",
      "邮编：100028\n",
      "网址：www.hxph.com.cn\n",
      "电话：(010)64663331(转)\n",
      "若发现本版图书有印装质量问题，请与我社营销中心联系调换．\n",
      "有关非暴力沟通的更多信息，请联系非暴力沟通中心，地址如下\n",
      "Center for Nonviolent Communication (CNVC)\n",
      "9301 Indian School Rd., NE, Suite 204Albuquerque NM 87112-2861 USA\n",
      "Ph: 505-244-4041\n",
      "US Only: 800-255-7696\n",
      "Fax: 505-247-0414\n",
      "Email: cnvc@CNVC.org\n",
      "Website: www.CNVC.org\n",
      "目录\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# print(documents[0])\n",
    "print(len(documents))\n",
    "# 输出到txt文件中把所有节点信息\n",
    "print(documents[0].text)\n",
    "print(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NarrativeText', 'Title', 'UncategorizedText'}\n",
      "最长内容长度: 13639\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "nodes_list = []\n",
    "node_category = set()\n",
    "# 检查所有节点的metadata中一共出现了哪几种category\n",
    "# 记录过程中最长的内容长度\n",
    "max_text_len = 0\n",
    "for doc in llamindex_docs:\n",
    "    node_category.add(doc.metadata[\"category\"])\n",
    "    node_data = {\n",
    "        \"text\": doc.text,\n",
    "        \"metadata\": doc.metadata,\n",
    "        \"text_len\": len(doc.text),\n",
    "    }\n",
    "    nodes_list.append(node_data)\n",
    "    if len(doc.text) > max_text_len:\n",
    "        max_text_len = len(doc.text)\n",
    "print(node_category)\n",
    "print(f\"最长内容长度: {max_text_len}\")\n",
    "\n",
    "# 保存到 json 文件\n",
    "# with open(\"非暴力沟通md.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(nodes_list, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现，加载后的段落更完整，更符合直觉的按照章节内容分割成多个节点了，这样可以进一步操作，构建多层级节点，同时也可以去生成一些更好的总结性的文本作为节点内容\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentence splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "from readai.components.text_splitters.splitters import SentenceSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手动调用SentenceSplitter来查看其行为\n",
    "ingest_docs = [\n",
    "    Document(text=doc.page_content, metadata=doc.metadata) for doc in documents\n",
    "]\n",
    "# 对一个doc进行分割后查看细节\n",
    "test_text = ingest_docs[0].text\n",
    "test_splits = SentenceSplitter.split_text(test_text)\n",
    "print(f\"原文长度: {len(test_text)}, 分割后片段数: {len(test_splits)}\")\n",
    "# 检查原文以及分割后的结果\n",
    "print(test_text)\n",
    "print(\"-\" * 100)\n",
    "for text in test_splits:\n",
    "    print(text)\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_docs = [\n",
    "    Document(text=doc.page_content, metadata=doc.metadata) for doc in documents\n",
    "]\n",
    "# 创建SentenceSplitter实例\n",
    "sentence_splitter = SentenceSplitter(\n",
    "    chunk_size=512,  # 每个块的最大token数\n",
    "    chunk_overlap=50,  # 块之间的重叠token数\n",
    "    include_metadata=True,  # 包含元数据\n",
    "    include_prev_next_rel=True,  # 维护块之间的前后关系\n",
    ")\n",
    "\n",
    "# 直接调用spltter的方式\n",
    "processed_nodes = sentence_splitter.get_nodes_from_documents(\n",
    "    ingest_docs, show_progress=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n"
     ]
    }
   ],
   "source": [
    "# 查看node有哪些属性,按照json格式输出\n",
    "print(len(processed_nodes))\n",
    "# processed_nodes节点输出全部看看,保存内容到json文件中\n",
    "with open(\"processed_nodes.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for node in processed_nodes:\n",
    "        # 数据转json\n",
    "        json_data = json.dumps(node.to_dict(), ensure_ascii=False, indent=2)\n",
    "        f.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比几种node parser策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_nodes = llamindex_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x3150ac9d0>, id_func=<function default_id_func at 0x10b1283a0>, chunk_size=1024, chunk_overlap=50, separator='\\n\\n', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.core.schema import IndexNode\n",
    "\n",
    "node_parser = SimpleNodeParser.from_defaults(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=50,\n",
    "    separator=\"\\n\\n\",\n",
    "    secondary_chunking_regex=\"[^,.;。？！]+[,.;。？！]?\",\n",
    ")\n",
    "node_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_parser.chunk_size\n",
    "node_parser.chunk_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb4be17674c40188afcbf17cdb0747c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 采用默认的sentence splitter分块\n",
    "base_nodes = node_parser.get_nodes_from_documents(llamindex_docs, show_progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "print(len(base_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'马歇尔·卢森堡博士发现了一种沟通方式，依照它来谈话和聆听，能使人们情意相通，和谐相处，这就是“非暴力沟通”。 做为一个遵纪守法的好人，也许我们从来没有把谈话和“暴力”扯上关系。不过如果稍微留意一下现实生活中的谈话方式，并且用心体会各种谈话方式给我们的不同感受，我们一定会发现，有些话确实伤人！言语上的指责、嘲讽、否定、说教以及任意打断、拒不回应、随意出口的评价和结论给我们带来的情感和精神上的创伤甚至比肉体的伤害更加令人痛苦。这些无心或有意的语言暴力让人与人变得冷漠、隔膜、敌视。 非暴力沟通能够： ● 疗愈内心深处的隐秘伤痛； ● 超越个人心智和情感的局限性； ● 突破那些引发愤怒、沮丧、焦虑等负面情绪的思维方式； ● 用不带伤害的方式化解人际间的冲突； ● 学会建立和谐的生命体验。 图书在版编目(CIP)数据 非暴力沟通／（美）马歇尔·卢森堡（Marshall B.Rosenberg）著；刘轶译.-2版（修订本）-北京：华夏出版社有限公司，2021.5 书名原文：Nonviolent Communication ISBN 978-7-5222-0051-4 Ⅰ.①非⋯Ⅱ.①马⋯②刘⋯Ⅲ.①心理交往-通俗读物Ⅳ.①C912.11-49 中国版本图书馆CIP数据核字（2021）第006542号 Translated from the book Nonviolent Communication:A Language of Life 3rd Edition,ISBN 13/10:9781892005281/189200528X by Marshall B.Rosenberg. Copyright ? Fall 2015 Puddle Dancer Press,published by Puddle Dancer Press. All rights reserved. Used with permission. For further information about Nonviolent Communication(TM) please visit the Center for Nonviolent Communication on the Web at:www.cnvc.org.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_nodes[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, node in enumerate(base_nodes):\n",
    "#     node.id_ = str(idx)\n",
    "# 不能自己改了，有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.deepseek import DeepSeek\n",
    "\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "model_name = os.getenv(\"DEEPSEEK_MODEL\")\n",
    "embed_model = OllamaEmbedding(\n",
    "    model_name=\"quentinz/bge-large-zh-v1.5\", base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "# 设置 LLM\n",
    "llm = DeepSeek(model=model_name, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建index,retriever,query_engine\n",
    "from llama_index.core.indices.vector_store.base import VectorStoreIndex\n",
    "from llama_index.core.storage import StorageContext\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient, AsyncQdrantClient\n",
    "\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "aclient = AsyncQdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "向量初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集合 'base_nodes' 已存在\n",
      "加载本地向量完成\n"
     ]
    }
   ],
   "source": [
    "# 如果是传入了nodes类型，直接用类初始化，如果是docs则用from_documents初始化\n",
    "vector_store_base = QdrantVectorStore(\n",
    "    client=client,\n",
    "    aclient=aclient,\n",
    "    collection_name=\"base_nodes\",\n",
    ")\n",
    "\n",
    "collection_name = \"base_nodes\"\n",
    "base_index = None\n",
    "if client.collection_exists(collection_name):\n",
    "    print(f\"集合 '{collection_name}' 已存在\")\n",
    "    base_index = VectorStoreIndex.from_vector_store(\n",
    "        vector_store_base, embed_model=embed_model\n",
    "    )\n",
    "    print(\"加载本地向量完成\")\n",
    "else:\n",
    "    print(f\"集合 '{collection_name}' 不存在，需要初始化\")\n",
    "    qdrant_storage_context = StorageContext.from_defaults(\n",
    "        vector_store=vector_store_base\n",
    "    )\n",
    "    base_index = VectorStoreIndex(\n",
    "        base_nodes,\n",
    "        embed_model=embed_model,\n",
    "        llm=llm,\n",
    "        storage_context=qdrant_storage_context,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    print(\"初始化本地向量完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_retriever = base_index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievals = base_retriever.retrieve(\n",
    "    \"在日常交流中，我们如何区分客观的观察和主观的评价？\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** c5bc47b6-b0d0-4a31-bf2c-cde6f90e2131<br>**Similarity:** 0.65816826<br>**Text:** 会议最后，我们商量了一些办法，以后当老师们不想听校长回忆往事时，就用温和的方式提醒他。 区分观察和评论 在以下列表中，我举例说明如何从混杂着评论的句子中区分出观察。 续表 注意：总是、永远、从来、每次之类的词语在以下用法中表达的是观察： ·每次我看到杰克打电话，他都至少打半小时。 ·我记得你从来没有写信给我。 然而有时，这些词是言过其实的表达，混淆了观察和评论： ·你总是在忙。 ·在需要她的时候，她永远都不在。 这样的表达经常会引发他人的逆反心理，而非慈悲之情。 “经常”“很少”这样的词也可能混淆观察和评论。 小结 非暴力沟通的第一个要素是区分观察与评论。当我们在观察中夹杂着自己的评论时，他人往往会认为我们在批评他们，并因而产生抗拒的心理。<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** e87f01ad-2d1b-4eba-989c-7a1003652c07<br>**Similarity:** 0.62561125<br>**Text:** 去观察，就像信仰一样重要。 ——弗雷德里克·布希纳（Frederick Buechner） 我欣然接受你告诉我， 我做了什么或者我未做什么。 我也欣然接受你的评论， 但请不要将两者混淆。 如果你想把事情搅乱， 我可以告诉你如何做到： 将我做的事情 和你的反应混为一谈。 当你见到做了一半的家务活， 可以告诉我你感到失望。 但说我不负责任， 绝无可能让我做得更多。 当我对你的表白说“不”， 请告诉我你感到伤心。 但说我冷酷无情， 并不能给你带来更多机会。 是的， 我欣然接受你告诉我， 我做了什么或者我未做什么。 我也欣然接受你的评论， 但请不要将两者混淆。 ——马歇尔·卢森堡博士 非暴力沟通的第一个要素是区分观察与评论。我们要清楚地观察有哪些所见、所闻和所触，正影响着我们幸福，而不夹杂任何评论。 在非暴力沟通中，当我们想要清晰且诚恳地向他人表达我们的状态时，“观察”是一个重要的要素。<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 7c6c297e-5946-4433-975f-c6d5013faa86<br>**Similarity:** 0.62505203<br>**Text:** ” 就像这个故事所展现的，从我们的旧习惯中挣脱出来，并有能力熟练地区分观察与评论并不容易。最终，老师们终于可以明明白白地告诉校长，他们对他的哪些行为感到不满。校长认真地听完后郑重地说：“为什么从没有人告诉我呢？”他承认他有讲故事的习惯，接着就开始说与这个习惯有关的故事了！我见状打断了他的话，婉转地提出他在重蹈覆辙。会议最后，我们商量了一些办法，以后当老师们不想听校长回忆往事时，就用温和的方式提醒他。 区分观察和评论 在以下列表中，我举例说明如何从混杂着评论的句子中区分出观察。 续表 注意：总是、永远、从来、每次之类的词语在以下用法中表达的是观察： ·每次我看到杰克打电话，他都至少打半小时。 ·我记得你从来没有写信给我。 然而有时，这些词是言过其实的表达，混淆了观察和评论： ·你总是在忙。 ·在需要她的时候，她永远都不在。 这样的表达经常会引发他人的逆反心理，而非慈悲之情。 “经常”“很少”这样的词也可能混淆观察和评论。<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 64e60b97-d59a-4a5a-9d11-9815d748047b<br>**Similarity:** 0.6229984<br>**Text:** 因此，尽管有许多困难，我依然愿意坚持尝试这个方法。 练习一：观察还是评论？ 请完成以下练习，看看你是否可以熟练区分观察和评论。请标出那些只是描述观察而不带有评论的句子。 1. “昨天，约翰无缘无故冲我发脾气。” 2. “昨天晚上，南希一边看电视、一边咬指甲。” 3. “会议上我没有听到桑姆询问我的意见。” 4. “我的父亲是个好人。” 5. “詹尼斯花在工作上的时间太多了。” 6. “亨利很强势。” 7. “这周，潘每天第一个来排队。” 8. “我的儿子经常不刷牙。” 9. “卢克说，我穿黄色衣服不好看。” 10.“姑姑和我说话时一直在抱怨。” 以下是我对练习一的回应： 1.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for n in retrievals:\n",
    "    display_source_node(n, source_length=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用retrieverqueryengine\n",
    "query_engine_base = RetrieverQueryEngine.from_args(base_retriever, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在日常交流中，区分客观观察和主观评价的关键在于是否包含个人判断或情绪。客观观察应仅描述具体事实或行为，而不附加解释或定性。例如，\"南希一边看电视一边咬指甲\"是观察，而\"詹尼斯花在工作上的时间太多了\"则隐含了评价。使用绝对化词语（如\"总是\"\"从不\"）时需谨慎，这类表达往往将观察夸大成了评论。练习时可以先尝试剥离形容词和价值判断，只保留可验证的行为描述。当我们需要表达感受时，应当基于具体观察展开，而非直接给对方贴标签。这种区分能减少沟通中的对抗性，促进相互理解。\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_base.query(\"在日常交流中，我们如何区分客观的观察和主观的评价？\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 采用分级摘要,small2big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2753\n"
     ]
    }
   ],
   "source": [
    "sub_chunk_sizes = [128, 512, 2048]\n",
    "sub_node_parsers = [\n",
    "    SimpleNodeParser.from_defaults(\n",
    "        chunk_size=c,\n",
    "        chunk_overlap=50,\n",
    "        separator=\"\\n\\n\",\n",
    "        secondary_chunking_regex=\"[^,.;。？！]+[,.;。？！]?\",\n",
    "    )\n",
    "    for c in sub_chunk_sizes\n",
    "]\n",
    "\n",
    "all_nodes = []\n",
    "for base_node in base_nodes:\n",
    "    for n in sub_node_parsers:\n",
    "        sub_nodes = n.get_nodes_from_documents([base_node])\n",
    "        sub_inodes = [\n",
    "            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n",
    "        ]\n",
    "        all_nodes.extend(sub_inodes)\n",
    "\n",
    "    # also add original node to node\n",
    "    original_node = IndexNode.from_text_node(base_node, base_node.node_id)\n",
    "    all_nodes.append(original_node)\n",
    "\n",
    "print(len(all_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_dict = {n.node_id: n for n in all_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2753"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集合 'small2big_nodes' 已存在\n",
      "加载本地向量完成\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "\n",
    "collection_name = \"small2big_nodes\"\n",
    "vector_store_chunk = QdrantVectorStore(\n",
    "    client=client,\n",
    "    aclient=aclient,\n",
    "    collection_name=collection_name,\n",
    ")\n",
    "vector_chunk_index = None\n",
    "\n",
    "if client.collection_exists(collection_name):\n",
    "    print(f\"集合 '{collection_name}' 已存在\")\n",
    "    vector_chunk_index = VectorStoreIndex.from_vector_store(\n",
    "        vector_store_chunk, embed_model=embed_model\n",
    "    )\n",
    "    print(\"加载本地向量完成\")\n",
    "else:\n",
    "    print(f\"集合 '{collection_name}' 不存在，需要初始化\")\n",
    "    # build from nodes\n",
    "    qdrant_storage_context = StorageContext.from_defaults(\n",
    "        vector_store=vector_store_chunk\n",
    "    )\n",
    "    vector_chunk_index = VectorStoreIndex(\n",
    "        all_nodes,\n",
    "        embed_model=embed_model,\n",
    "        storage_context=qdrant_storage_context,\n",
    "        show_progress=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever_chunk = vector_chunk_index.as_retriever(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: 在日常交流中，我们如何区分客观的观察和主观的评价？\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: df746b85-3568-48b2-9961-5bea0277c3f6\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id df746b85-3568-48b2-9961-5bea0277c3f6: 在日常交流中，我们如何区分客观的观察和主观的评价？\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** df746b85-3568-48b2-9961-5bea0277c3f6<br>**Similarity:** 0.6397337<br>**Text:** 当我指出这一点后，另一位老师响应道：“我知道他的意思了。校长的话太多！”这仍不是一个清晰的观察，而是对校长说多少话的评论。随后，第三位老师说：“他认为只有他想说的话是重要的。”我进而向他们解释，推断他人的想法和对他人行为的观察是两码事。随后，第四位老师大胆地说：“他总是想成为人前的焦点。”当我指出这也是推断时，两位老师不约而同地说道：“你的问题太难回答了！” 接着，我们一起拟了份清单，明确列出校长有哪些具体行为令他们感到不满，并确保不掺杂评论。例如，在全体教师会议上，校长会讲述他的童年和战争经历，有时导致会议超时20分钟。我问老师们是否曾经和校长沟通过他们的不满，他们说曾经试过，但都用具有评论意味的言辞向校长提出批评，而从未提及任何具体行为，例如校长在会议中讲述自己的故事。最后，老师们同意在与校长会谈时将这一点提出来。 会谈刚一开始，我便目睹了老师们所描述的情景。不论讨论的主题是什么，校长都会插话说：“想当年……”接着开始讲述他的童年或战争经历。我等着老师们表达他们的不满。然而，他们并没有运用非暴力沟通的方式，而是无声的抗议。有的人开始翻白眼，有的人故意打着哈欠，还有个人一直盯着手表。 直到我按捺不住问他们：“没有人有话要说吗？”迎来的是一阵令人尴尬的沉默。接着，之前会谈中率先发言的那位老师鼓起勇气，直视着校长，然后说出：“艾德，你真是个大嘴巴！” 就像这个故事所展现的，从我们的旧习惯中挣脱出来，并有能力熟练地区分观察与评论并不容易。最终，老师们终于可以明明白白地告诉校长，他们对他的哪些行为感到不满。校长认真地听完后郑重地说：“为什么从没有人告诉我呢？”他承认他有讲故事的习惯，接着就开始说与这个习惯有关的故事了！我见状打断了他的话，婉转地提出他在重蹈覆辙。会议最后，我们商量了一些办法，以后当老师们不想听校长回忆往事时，就用温和的方式提醒他。 区分观察和评论 在以下列表中，我举例说明如何从混杂着评论的句子中区分出观察。 续表 注意：总是、永远、从来、每次之类的词语在以下用法中表达的是观察： ·每次我看到杰克打电话，他都至少打半小时。<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "nodes = retriever_chunk.retrieve(\"在日常交流中，我们如何区分客观的观察和主观的评价？\")\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_chunk = RetrieverQueryEngine.from_args(retriever_chunk, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: 在日常交流中，我们如何区分客观的观察和主观的评价？\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: df746b85-3568-48b2-9961-5bea0277c3f6\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id df746b85-3568-48b2-9961-5bea0277c3f6: 在日常交流中，我们如何区分客观的观察和主观的评价？\n",
      "\u001b[0m在日常交流中，区分客观观察和主观评价的关键在于是否包含个人判断或推测。客观观察应聚焦于具体、可验证的事实，而主观评价则往往带有个人观点或情感色彩。\n",
      "\n",
      "例如，说\"会议超时20分钟\"是观察，因为它陈述了可量化的事实；而说\"他话太多\"则是评价，因为包含了说话者对行为的主观判断。同样，\"他讲述了童年经历\"是观察，而\"他想成为焦点\"是评价。\n",
      "\n",
      "要有效区分两者，可以：\n",
      "1. 避免使用绝对化词汇（如总是、从不）\n",
      "2. 描述具体行为而非概括性格\n",
      "3. 确保陈述的内容可以被摄像机记录\n",
      "4. 将时间、地点等具体细节纳入描述\n",
      "\n",
      "这种区分需要练习，因为人们往往习惯于混合表达观察与评价。通过有意识地训练，我们能够更清晰地进行事实性沟通，减少因评价性语言引发的误解或冲突。\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_chunk.query(\n",
    "    \"在日常交流中，我们如何区分客观的观察和主观的评价？\"\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "2753\n"
     ]
    }
   ],
   "source": [
    "print(len(base_nodes))\n",
    "print(len(all_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nodes = base_nodes[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:19<00:00,  8.79s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = generate_question_context_pairs(test_nodes, llm=llm)\n",
    "eval_dataset.save_json(\"./feibaoli_eval_dataset50.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成答案测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llama_index.core.evaluation import RetrieverEvaluator, get_retrieval_results_df\n",
    "\n",
    "# set vector retriever similarity top k to higher\n",
    "top_k = 10\n",
    "\n",
    "\n",
    "def display_results(names, results_arr):\n",
    "    \"\"\"Display results from evaluate.\"\"\"\n",
    "\n",
    "    hit_rates = []\n",
    "    mrrs = []\n",
    "    for name, eval_results in zip(names, results_arr):\n",
    "        metric_dicts = []\n",
    "        for eval_result in eval_results:\n",
    "            metric_dict = eval_result.metric_vals_dict\n",
    "            metric_dicts.append(metric_dict)\n",
    "        results_df = pd.DataFrame(metric_dicts)\n",
    "\n",
    "        hit_rate = results_df[\"hit_rate\"].mean()\n",
    "        mrr = results_df[\"mrr\"].mean()\n",
    "        hit_rates.append(hit_rate)\n",
    "        mrrs.append(mrr)\n",
    "\n",
    "    final_df = pd.DataFrame({\"retrievers\": names, \"hit_rate\": hit_rates, \"mrr\": mrrs})\n",
    "    display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 35.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# base\n",
    "base_retriever = base_index.as_retriever(similarity_top_k=top_k)\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=base_retriever\n",
    ")\n",
    "\n",
    "# 异步并行评估需要qdrant aclient\n",
    "results_base = await retriever_evaluator.aevaluate_dataset(\n",
    "    eval_dataset, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk\n",
    "vector_retriever_chunk = vector_chunk_index.as_retriever(similarity_top_k=top_k)\n",
    "retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")\n",
    "retriever_evaluator_chunk = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=retriever_chunk\n",
    ")\n",
    "\n",
    "results_chunk = await retriever_evaluator_chunk.aevaluate_dataset(\n",
    "    eval_dataset, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base Retriever</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.099544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retriever (Chunk References)</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.444119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     retrievers  hit_rate       mrr\n",
       "0                Base Retriever      0.29  0.099544\n",
       "1  Retriever (Chunk References)      0.60  0.444119"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_results_df = get_retrieval_results_df(\n",
    "    [\"Base Retriever\", \"Retriever (Chunk References)\"],\n",
    "    [results_base, results_chunk],\n",
    ")\n",
    "display(full_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试中文问答题目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [09:15<00:00, 11.10s/it]\n"
     ]
    }
   ],
   "source": [
    "from readai.components.prompts import QA_GENERATE_PROMPT_TMPL_ZH\n",
    "\n",
    "eval_dataset_zh = generate_question_context_pairs(\n",
    "    test_nodes, llm=llm, qa_generate_prompt_tmpl=QA_GENERATE_PROMPT_TMPL_ZH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重写方法，保存中文内容\n",
    "import json\n",
    "\n",
    "path = \"./feibaoli_eval_dataset50_zh.json\"\n",
    "with open(path, \"w\") as f:\n",
    "    json.dump(eval_dataset_zh.model_dump(), f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 33.85it/s]\n"
     ]
    }
   ],
   "source": [
    "results_base_zh = await retriever_evaluator.aevaluate_dataset(\n",
    "    eval_dataset_zh, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_chunk_zh = await retriever_evaluator_chunk.aevaluate_dataset(\n",
    "    eval_dataset_zh, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base Retriever</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.093258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retriever (Chunk References)</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.549000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     retrievers  hit_rate       mrr\n",
       "0                Base Retriever      0.32  0.093258\n",
       "1  Retriever (Chunk References)      0.62  0.549000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_results_df_zh = get_retrieval_results_df(\n",
    "    [\"Base Retriever\", \"Retriever (Chunk References)\"],\n",
    "    [results_base_zh, results_chunk_zh],\n",
    ")\n",
    "display(full_results_df_zh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 探索TextNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import (\n",
    "    Document,\n",
    "    MetadataMode,\n",
    "    NodeRelationship,\n",
    "    TextNode,\n",
    "    NodeWithScore,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 检索阶段\n",
    "from llama_index.core.retrievers import AutoMergingRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# 基础向量检索器\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=3)\n",
    "\n",
    "# 自动合并检索器\n",
    "auto_retriever = AutoMergingRetriever(\n",
    "    base_retriever=vector_retriever, storage_context=storage_context\n",
    ")\n",
    "\n",
    "# 查询引擎\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever=auto_retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 思考\n",
    "- 为什么要转换成markdown\n",
    "因为转换成markdown后，原本epub文件是存在一些结构性内容的，比如标题的层级，相比直接按照epub内容（转html）被读取，转换成markdown后，这种层级内容更加清晰，而且我更好处理\n",
    "- 转换后为什么还要去除一些无效符号？（比如空行）\n",
    "因为目前很多中文分块策略，在区分段落时会根据两个换行符区分，但转markdown后发现有很多多余的空行,清除掉多余的空行其实是可以更方便使用text_spliiter的\n",
    "\n",
    "- 要使用哪一种chunk或node parser策略？\n",
    "    - small2big\n",
    "    - 句子分割 sentence splitter\n",
    "- query优化\n",
    "- 后处理手段\n",
    "    - rereank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readai-vv5wOT8E-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
