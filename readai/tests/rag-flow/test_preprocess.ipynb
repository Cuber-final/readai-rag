{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import (\n",
    "    UnstructuredEPubLoader,\n",
    "    UnstructuredMarkdownLoader,\n",
    ")\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "# 加载.env文件\n",
    "load_dotenv()\n",
    "\n",
    "# 获取项目根目录路径\n",
    "project_root = Path(os.getenv(\"PROJECT_ROOT\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = project_root / \"readai/tests/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用epubloader，效果不太理想"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点数量: 1795\n"
     ]
    }
   ],
   "source": [
    "# 第一步：使用 UnstructuredEPubLoader 加载 EPUB 文档\n",
    "# 读取PROJECT_ROOT\n",
    "\n",
    "book_name = \"非暴力沟通.epub\"\n",
    "book_path = test_data_path / book_name\n",
    "loader = UnstructuredEPubLoader(book_path, mode=\"elements\", strategy=\"fast\")\n",
    "documents = loader.load()\n",
    "print(f\"节点数量: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epub转markdown\n",
    "- 优点是处理起来更好更方便，可以在load之前还进一步对文本清洗，过滤多余的空行，让内容更接近原本的段落，章节形式\n",
    "- 使用UnstructuredMarkdownLoader读取，但会存在很多用不上的metadata属性，所以需要删除过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点数量: 41\n"
     ]
    }
   ],
   "source": [
    "book_name = \"comunication_cleaned.md\"\n",
    "book_path = test_data_path / book_name\n",
    "# 使用unstructured的markdownloader加载\n",
    "loader = UnstructuredMarkdownLoader(book_path, mode=\"elements\")\n",
    "documents = loader.load()\n",
    "# 查看节点数量\n",
    "print(f\"节点数量: {len(documents)}\")\n",
    "# 遍历documents,重构metadata，只保留category，filename这两个属性\n",
    "for doc in documents:\n",
    "    category = doc.metadata[\"category\"]\n",
    "    filename = doc.metadata[\"filename\"]\n",
    "    doc.metadata = {\n",
    "        \"category\": category,\n",
    "        \"filename\": filename,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LLM sees this:\n",
      " Metadata: category=>NarrativeText::filename=>comunication_cleaned.md\n",
      "-----\n",
      "Content: 马歇尔·卢森堡博士发现了一种沟通方式，依照它来谈话和聆听，能使人们情意相通，和谐相处，这就是“非暴力沟通”。 做为一个遵纪守法的好人，也许我们从来没有把谈话和“暴力”扯上关系。不过如果稍微留意一下现实生活中的谈话方式，并且用心体会各种谈话方式给我们的不同感受，我们一定会发现，有些话确实伤人！言语上的指责、嘲讽、否定、说教以及任意打断、拒不回应、随意出口的评价和结论给我们带来的情感和精神上的创伤甚至比肉体的伤害更加令人痛苦。这些无心或有意的语言暴力让人与人变得冷漠、隔膜、敌视。 非暴力沟通能够： ● 疗愈内心深处的隐秘伤痛； ● 超越个人心智和情感的局限性； ● 突破那些引发愤怒、沮丧、焦虑等负面情绪的思维方式； ● 用不带伤害的方式化解人际间的冲突； ● 学会建立和谐的生命体验。 图书在版编目(CIP)数据 非暴力沟通／（美）马歇尔·卢森堡（Marshall B.Rosenberg）著；刘轶译.-2版（修订本）-北京：华夏出版社有限公司，2021.5 书名原文：Nonviolent Communication ISBN 978-7-5222-0051-4 Ⅰ.①非⋯Ⅱ.①马⋯②刘⋯Ⅲ.①心理交往-通俗读物Ⅳ.①C912.11-49 中国版本图书馆CIP数据核字（2021）第006542号 Translated from the book Nonviolent Communication:A Language of Life 3rd Edition,ISBN 13/10:9781892005281/189200528X by Marshall B.Rosenberg. Copyright ? Fall 2015 Puddle Dancer Press,published by Puddle Dancer Press. All rights reserved. Used with permission. For further information about Nonviolent Communication(TM) please visit the Center for Nonviolent Communication on the Web at:www.cnvc.org. 版权所有翻印必究 北京市版权局著作权合同登记号：图字01-2016-2253号 非暴力沟通 著 者 [美]马歇尔·卢森堡 译 者 刘 轶 责任编辑 朱 悦 责任印制 刘 洋 出版发行 华夏出版社 经 销 新华书店 印 刷 三河市少明印务有限公司 装 订 三河市少明印务有限公司 版 次 2021年5月北京第2版 2021年5月北京第1次印刷 开 本 720x1030 1/16开 印 张 16 彩 页 6页 字 数 190千字 定 价 59.80元 华夏出版社有限公司 地址：北京市东直门外香河园北里4号 邮编：100028 网址：www.hxph.com.cn 电话：(010)64663331(转) 若发现本版图书有印装质量问题，请与我社营销中心联系调换． 有关非暴力沟通的更多信息，请联系非暴力沟通中心，地址如下 Center for Nonviolent Communication (CNVC) 9301 Indian School Rd., NE, Suite 204Albuquerque NM 87112-2861 USA Ph: 505-244-4041 US Only: 800-255-7696 Fax: 505-247-0414 Email: cnvc@CNVC.org Website: www.CNVC.org 目录\n",
      "The Embedding model sees this: \n",
      " Metadata: category=>NarrativeText::filename=>comunication_cleaned.md\n",
      "-----\n",
      "Content: 马歇尔·卢森堡博士发现了一种沟通方式，依照它来谈话和聆听，能使人们情意相通，和谐相处，这就是“非暴力沟通”。 做为一个遵纪守法的好人，也许我们从来没有把谈话和“暴力”扯上关系。不过如果稍微留意一下现实生活中的谈话方式，并且用心体会各种谈话方式给我们的不同感受，我们一定会发现，有些话确实伤人！言语上的指责、嘲讽、否定、说教以及任意打断、拒不回应、随意出口的评价和结论给我们带来的情感和精神上的创伤甚至比肉体的伤害更加令人痛苦。这些无心或有意的语言暴力让人与人变得冷漠、隔膜、敌视。 非暴力沟通能够： ● 疗愈内心深处的隐秘伤痛； ● 超越个人心智和情感的局限性； ● 突破那些引发愤怒、沮丧、焦虑等负面情绪的思维方式； ● 用不带伤害的方式化解人际间的冲突； ● 学会建立和谐的生命体验。 图书在版编目(CIP)数据 非暴力沟通／（美）马歇尔·卢森堡（Marshall B.Rosenberg）著；刘轶译.-2版（修订本）-北京：华夏出版社有限公司，2021.5 书名原文：Nonviolent Communication ISBN 978-7-5222-0051-4 Ⅰ.①非⋯Ⅱ.①马⋯②刘⋯Ⅲ.①心理交往-通俗读物Ⅳ.①C912.11-49 中国版本图书馆CIP数据核字（2021）第006542号 Translated from the book Nonviolent Communication:A Language of Life 3rd Edition,ISBN 13/10:9781892005281/189200528X by Marshall B.Rosenberg. Copyright ? Fall 2015 Puddle Dancer Press,published by Puddle Dancer Press. All rights reserved. Used with permission. For further information about Nonviolent Communication(TM) please visit the Center for Nonviolent Communication on the Web at:www.cnvc.org. 版权所有翻印必究 北京市版权局著作权合同登记号：图字01-2016-2253号 非暴力沟通 著 者 [美]马歇尔·卢森堡 译 者 刘 轶 责任编辑 朱 悦 责任印制 刘 洋 出版发行 华夏出版社 经 销 新华书店 印 刷 三河市少明印务有限公司 装 订 三河市少明印务有限公司 版 次 2021年5月北京第2版 2021年5月北京第1次印刷 开 本 720x1030 1/16开 印 张 16 彩 页 6页 字 数 190千字 定 价 59.80元 华夏出版社有限公司 地址：北京市东直门外香河园北里4号 邮编：100028 网址：www.hxph.com.cn 电话：(010)64663331(转) 若发现本版图书有印装质量问题，请与我社营销中心联系调换． 有关非暴力沟通的更多信息，请联系非暴力沟通中心，地址如下 Center for Nonviolent Communication (CNVC) 9301 Indian School Rd., NE, Suite 204Albuquerque NM 87112-2861 USA Ph: 505-244-4041 US Only: 800-255-7696 Fax: 505-247-0414 Email: cnvc@CNVC.org Website: www.CNVC.org 目录\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "llamindex_docs = [\n",
    "    Document(\n",
    "        text=doc.page_content,\n",
    "        metadata=doc.metadata,\n",
    "        metadata_seperator=\"::\",\n",
    "        metadata_template=\"{key}=>{value}\",\n",
    "        text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n",
    "    )\n",
    "    for doc in documents\n",
    "]\n",
    "print(\n",
    "    \"The LLM sees this:\\n\",\n",
    "    llamindex_docs[0].get_content(metadata_mode=MetadataMode.LLM),\n",
    ")\n",
    "print(\n",
    "    \"The Embedding model sees this: \\n\",\n",
    "    llamindex_docs[0].get_content(metadata_mode=MetadataMode.EMBED),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(llamindex_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c5eae06a-eef8-4871-9239-9193c0354169'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llamindex_docs[0].doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 查看node有哪些属性,按照json格式输出\n",
    "print(len(llamindex_docs))\n",
    "# processed_nodes节点输出全部看看,保存内容到json文件中\n",
    "with open(\"llamindex_docs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for node in llamindex_docs:\n",
    "        # 数据转json\n",
    "        json_data = json.dumps(node.to_dict(), ensure_ascii=False, indent=2)\n",
    "        f.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用LLamaindex的MarkdownReader加载,效果不如unstructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'header_path': '/'}\n",
      "# 致谢\n",
      "感谢卡尔·罗杰斯（Carl Rogers）教授，当他正在研究“有益于人际关系的要素”这一课题时，我有幸向他学习并与他共事。这项研究的结果在我发展“非暴力沟通”的过程中至关重要。\n",
      "xxxx\n",
      "{'header_path': '/'}\n",
      "# 第一章　由衷的给予\n",
      "我渴望我的生命活出善意和慈悲（Compassion），\n",
      "由衷的给予在你我之间流动。\n",
      "asdaxc\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "# 你提供的 Markdown 文本（可以从 .md 文件读取，这里直接写入变量）\n",
    "markdown_text = \"\"\"\n",
    "# 致谢\n",
    "感谢卡尔·罗杰斯（Carl Rogers）教授，当他正在研究“有益于人际关系的要素”这一课题时，我有幸向他学习并与他共事。这项研究的结果在我发展“非暴力沟通”的过程中至关重要。\n",
    "xxxx\n",
    "\n",
    "# 第一章　由衷的给予\n",
    "我渴望我的生命活出善意和慈悲（Compassion），\n",
    "由衷的给予在你我之间流动。\n",
    "asdaxc\n",
    "\"\"\"\n",
    "\n",
    "# 1. 将 Markdown 文本构造成 LlamaIndex 的 Document\n",
    "document = Document(text=markdown_text)\n",
    "\n",
    "# 2. 创建 MarkdownNodeParser，按标题切割\n",
    "parser = MarkdownNodeParser()\n",
    "nodes = parser.get_nodes_from_documents([document], metadata_mode=MetadataMode.ALL)\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.metadata)\n",
    "    print(node.text)\n",
    "# 3. 打印每章的标题（来自 metadata）和内容预览\n",
    "# for i, node in enumerate(nodes):\n",
    "#     print(f\"\\n📘 第 {i + 1} 章 - 标题：{node.metadata.get('heading')}\")\n",
    "#     print(\"内容预览：\")\n",
    "#     print(node.text[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NarrativeText', 'Title', 'UncategorizedText'}\n",
      "最长内容长度: 13639\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "nodes_list = []\n",
    "node_category = set()\n",
    "# 检查所有节点的metadata中一共出现了哪几种category\n",
    "# 记录过程中最长的内容长度\n",
    "max_text_len = 0\n",
    "for doc in llamindex_docs:\n",
    "    node_category.add(doc.metadata[\"category\"])\n",
    "    node_data = {\n",
    "        \"text\": doc.text,\n",
    "        \"metadata\": doc.metadata,\n",
    "        \"text_len\": len(doc.text),\n",
    "    }\n",
    "    nodes_list.append(node_data)\n",
    "    if len(doc.text) > max_text_len:\n",
    "        max_text_len = len(doc.text)\n",
    "print(node_category)\n",
    "print(f\"最长内容长度: {max_text_len}\")\n",
    "\n",
    "# 保存到 json 文件\n",
    "# with open(\"非暴力沟通md.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(nodes_list, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现，加载后的段落更完整，更符合直觉的按照章节内容分割成多个节点了，这样可以进一步操作，构建多层级节点，同时也可以去生成一些更好的总结性的文本作为节点内容\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentence splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from readai.components.text_splitters.splitters import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手动调用SentenceSplitter来查看其行为\n",
    "ingest_docs = [\n",
    "    Document(text=doc.page_content, metadata=doc.metadata) for doc in documents\n",
    "]\n",
    "# 对一个doc进行分割后查看细节\n",
    "test_text = ingest_docs[0].text\n",
    "test_splits = SentenceSplitter.split_text(test_text)\n",
    "print(f\"原文长度: {len(test_text)}, 分割后片段数: {len(test_splits)}\")\n",
    "# 检查原文以及分割后的结果\n",
    "print(test_text)\n",
    "print(\"-\" * 100)\n",
    "for text in test_splits:\n",
    "    print(text)\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_docs = [\n",
    "    Document(text=doc.page_content, metadata=doc.metadata) for doc in documents\n",
    "]\n",
    "# 创建SentenceSplitter实例\n",
    "sentence_splitter = SentenceSplitter(\n",
    "    chunk_size=512,  # 每个块的最大token数\n",
    "    chunk_overlap=50,  # 块之间的重叠token数\n",
    "    include_metadata=True,  # 包含元数据\n",
    "    include_prev_next_rel=True,  # 维护块之间的前后关系\n",
    ")\n",
    "\n",
    "# 直接调用spltter的方式\n",
    "processed_nodes = sentence_splitter.get_nodes_from_documents(\n",
    "    ingest_docs, show_progress=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n"
     ]
    }
   ],
   "source": [
    "# 查看node有哪些属性,按照json格式输出\n",
    "print(len(processed_nodes))\n",
    "# processed_nodes节点输出全部看看,保存内容到json文件中\n",
    "with open(\"processed_nodes.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for node in processed_nodes:\n",
    "        # 数据转json\n",
    "        json_data = json.dumps(node.to_dict(), ensure_ascii=False, indent=2)\n",
    "        f.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比几种node parser策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_nodes = llamindex_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x3150ac9d0>, id_func=<function default_id_func at 0x10b1283a0>, chunk_size=1024, chunk_overlap=50, separator='\\n\\n', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.core.schema import IndexNode\n",
    "\n",
    "node_parser = SimpleNodeParser.from_defaults(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=50,\n",
    "    separator=\"\\n\\n\",\n",
    "    secondary_chunking_regex=\"[^,.;。？！]+[,.;。？！]?\",\n",
    ")\n",
    "node_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_parser.chunk_size\n",
    "node_parser.chunk_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb4be17674c40188afcbf17cdb0747c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 采用默认的sentence splitter分块\n",
    "base_nodes = node_parser.get_nodes_from_documents(llamindex_docs, show_progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "print(len(base_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'马歇尔·卢森堡博士发现了一种沟通方式，依照它来谈话和聆听，能使人们情意相通，和谐相处，这就是“非暴力沟通”。 做为一个遵纪守法的好人，也许我们从来没有把谈话和“暴力”扯上关系。不过如果稍微留意一下现实生活中的谈话方式，并且用心体会各种谈话方式给我们的不同感受，我们一定会发现，有些话确实伤人！言语上的指责、嘲讽、否定、说教以及任意打断、拒不回应、随意出口的评价和结论给我们带来的情感和精神上的创伤甚至比肉体的伤害更加令人痛苦。这些无心或有意的语言暴力让人与人变得冷漠、隔膜、敌视。 非暴力沟通能够： ● 疗愈内心深处的隐秘伤痛； ● 超越个人心智和情感的局限性； ● 突破那些引发愤怒、沮丧、焦虑等负面情绪的思维方式； ● 用不带伤害的方式化解人际间的冲突； ● 学会建立和谐的生命体验。 图书在版编目(CIP)数据 非暴力沟通／（美）马歇尔·卢森堡（Marshall B.Rosenberg）著；刘轶译.-2版（修订本）-北京：华夏出版社有限公司，2021.5 书名原文：Nonviolent Communication ISBN 978-7-5222-0051-4 Ⅰ.①非⋯Ⅱ.①马⋯②刘⋯Ⅲ.①心理交往-通俗读物Ⅳ.①C912.11-49 中国版本图书馆CIP数据核字（2021）第006542号 Translated from the book Nonviolent Communication:A Language of Life 3rd Edition,ISBN 13/10:9781892005281/189200528X by Marshall B.Rosenberg. Copyright ? Fall 2015 Puddle Dancer Press,published by Puddle Dancer Press. All rights reserved. Used with permission. For further information about Nonviolent Communication(TM) please visit the Center for Nonviolent Communication on the Web at:www.cnvc.org.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_nodes[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, node in enumerate(base_nodes):\n",
    "#     node.id_ = str(idx)\n",
    "# 不能自己改了，有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.deepseek import DeepSeek\n",
    "\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "model_name = os.getenv(\"DEEPSEEK_MODEL\")\n",
    "embed_model = OllamaEmbedding(\n",
    "    model_name=\"quentinz/bge-large-zh-v1.5\", base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "# 设置 LLM\n",
    "llm = DeepSeek(model=model_name, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建index,retriever,query_engine\n",
    "from llama_index.core.indices.vector_store.base import VectorStoreIndex\n",
    "from llama_index.core.storage import StorageContext\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from qdrant_client import AsyncQdrantClient, QdrantClient\n",
    "\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "aclient = AsyncQdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "向量初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集合 'hybrid_nodes' 已存在\n",
      "加载本地向量完成\n"
     ]
    }
   ],
   "source": [
    "# 如果是传入了nodes类型，直接用类初始化，如果是docs则用from_documents初始化\n",
    "vector_store_base = QdrantVectorStore(\n",
    "    client=client,\n",
    "    aclient=aclient,\n",
    "    collection_name=\"hybrid_nodes\",\n",
    ")\n",
    "\n",
    "collection_name = \"hybrid_nodes\"\n",
    "base_index = None\n",
    "if client.collection_exists(collection_name):\n",
    "    print(f\"集合 '{collection_name}' 已存在\")\n",
    "    base_index = VectorStoreIndex.from_vector_store(\n",
    "        vector_store_base, embed_model=embed_model\n",
    "    )\n",
    "    print(\"加载本地向量完成\")\n",
    "else:\n",
    "    print(f\"集合 '{collection_name}' 不存在，需要初始化\")\n",
    "    qdrant_storage_context = StorageContext.from_defaults(\n",
    "        vector_store=vector_store_base\n",
    "    )\n",
    "    base_index = VectorStoreIndex(\n",
    "        base_nodes,\n",
    "        embed_model=embed_model,\n",
    "        llm=llm,\n",
    "        storage_context=qdrant_storage_context,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    print(\"初始化本地向量完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_retriever = base_index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievals = base_retriever.retrieve(\n",
    "    \"在日常交流中，我们如何区分客观的观察和主观的评价？\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 801f9561-01f1-4776-8477-3d3b7b3ad7ca<br>**Similarity:** 0.6397337<br>**Text:** 我等着老师们表达他们的不满。然而，他们并没有运用非暴力沟通的方式，而是无声的抗议。有的人开始翻白眼，有的人故意打着哈欠，还有个人一直盯着手表。 直到我按捺不住问他们：“没有人有话要说吗？”迎来的是一阵令人尴尬的沉默。接着，之前会谈中率先发言的那位老师鼓起勇气，直视着校长，然后说出：“艾德，你真是个大嘴巴！” 就像这个故事所展现的，从我们的旧习惯中挣脱出来，并有能力熟练地区分观察与评论并不容易。最终，老师们终于可以明明白白地告诉校长，他们对他的哪些行为感到不满。校长认真地听完后郑重地说：“为什么从没有人告诉我呢？”他承认他有讲故事的习惯，接着就开始说与这个习惯有关的故事了！我见状打断了他的话，婉转地提出他在重蹈覆辙。会议最后，我们商量了一些办法，以后当老师们不想听校长回忆往事时，就用温和的方式提醒他。 区分观察和评论 在以下列表中，我举例说明如何从混杂着评论的句子中区分出观察。<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 28feb3d0-2b6d-48fc-9bc7-0cfe78fe9cc5<br>**Similarity:** 0.63871455<br>**Text:** 区分观察和评论 在以下列表中，我举例说明如何从混杂着评论的句子中区分出观察。 续表 注意：总是、永远、从来、每次之类的词语在以下用法中表达的是观察： ·每次我看到杰克打电话，他都至少打半小时。<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 5e879f54-accb-4c4b-8deb-f6d5e5fd5a1a<br>**Similarity:** 0.63314337<br>**Text:** 首先，我们观察实际上发生了什么。不论他人的言行是否有益于我们，我们只是去观察。要做到清晰表达所观察到的，我们的挑战在于不夹杂任何评判。不论喜欢与否，我们只是说出人们做了什么。<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 928f5556-aa7f-4ba2-8666-f4cd3432d39a<br>**Similarity:** 0.62933075<br>**Text:** 在非暴力沟通中，当我们想要清晰且诚恳地向他人表达我们的状态时，“观察”是一个重要的要素。如果我们在观察中夹杂着评论，人们便不那么容易真正听见我们想要表达的内容，反而会听到批评，甚至产生抗拒心理。<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for n in retrievals:\n",
    "    display_source_node(n, source_length=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用retrieverqueryengine\n",
    "query_engine_base = RetrieverQueryEngine.from_args(base_retriever, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在日常交流中，区分客观观察和主观评价的关键在于保持陈述的中立性和具体性。客观观察应当只描述实际发生的行为或事实，避免加入个人判断或情绪色彩。例如，直接说明\"杰克每次通话持续半小时\"是观察，而说\"杰克总是浪费工作时间打电话\"则包含了评价。\n",
      "\n",
      "要注意避免使用带有绝对性质的词语如\"总是\"、\"永远\"等，除非这些词语确实用于描述可验证的重复性事实。同时，保持对具体行为的关注，而不是对人格或动机的推测，这样能帮助我们将观察与评价清晰地区分开来。\n",
      "\n",
      "有效的观察应该让他人能够验证其真实性，而不会因为其中隐含的批评而产生防卫心理。当我们需要表达感受或需求时，可以在明确观察的基础上再进行陈述，这样既保持了沟通的清晰性，又减少了引发对抗的可能性。\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_base.query(\"在日常交流中，我们如何区分客观的观察和主观的评价？\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 采用分级摘要,small2big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2753\n"
     ]
    }
   ],
   "source": [
    "sub_chunk_sizes = [128, 512, 2048]\n",
    "sub_node_parsers = [\n",
    "    SimpleNodeParser.from_defaults(\n",
    "        chunk_size=c,\n",
    "        chunk_overlap=50,\n",
    "        separator=\"\\n\\n\",\n",
    "        secondary_chunking_regex=\"[^,.;。？！]+[,.;。？！]?\",\n",
    "    )\n",
    "    for c in sub_chunk_sizes\n",
    "]\n",
    "\n",
    "all_nodes = []\n",
    "for base_node in base_nodes:\n",
    "    for n in sub_node_parsers:\n",
    "        sub_nodes = n.get_nodes_from_documents([base_node])\n",
    "        sub_inodes = [\n",
    "            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n",
    "        ]\n",
    "        all_nodes.extend(sub_inodes)\n",
    "\n",
    "    # also add original node to node\n",
    "    original_node = IndexNode.from_text_node(base_node, base_node.node_id)\n",
    "    all_nodes.append(original_node)\n",
    "\n",
    "print(len(all_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_dict = {n.node_id: n for n in all_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2753"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.collection_exists(\"small2big_nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集合 'small2big_nodes' 已存在\n",
      "加载本地向量完成\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "\n",
    "collection_name = \"small2big_nodes\"\n",
    "vector_store_chunk = QdrantVectorStore(\n",
    "    client=client,\n",
    "    aclient=aclient,\n",
    "    collection_name=collection_name,\n",
    ")\n",
    "vector_chunk_index = None\n",
    "\n",
    "if client.collection_exists(collection_name):\n",
    "    print(f\"集合 '{collection_name}' 已存在\")\n",
    "    vector_chunk_index = VectorStoreIndex.from_vector_store(\n",
    "        vector_store_chunk, embed_model=embed_model\n",
    "    )\n",
    "    print(\"加载本地向量完成\")\n",
    "else:\n",
    "    print(f\"集合 '{collection_name}' 不存在，需要初始化\")\n",
    "    # build from nodes\n",
    "    qdrant_storage_context = StorageContext.from_defaults(\n",
    "        vector_store=vector_store_chunk\n",
    "    )\n",
    "    vector_chunk_index = VectorStoreIndex(\n",
    "        all_nodes,\n",
    "        embed_model=embed_model,\n",
    "        storage_context=qdrant_storage_context,\n",
    "        show_progress=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_dir = test_data_path / \"small2big_nodes\"\n",
    "vector_chunk_index.storage_context.persist(persist_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever_chunk = vector_chunk_index.as_retriever(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: 在日常交流中，我们如何区分客观的观察和主观的评价？\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: df746b85-3568-48b2-9961-5bea0277c3f6\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id df746b85-3568-48b2-9961-5bea0277c3f6: 在日常交流中，我们如何区分客观的观察和主观的评价？\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** df746b85-3568-48b2-9961-5bea0277c3f6<br>**Similarity:** 0.6397337<br>**Text:** 当我指出这一点后，另一位老师响应道：“我知道他的意思了。校长的话太多！”这仍不是一个清晰的观察，而是对校长说多少话的评论。随后，第三位老师说：“他认为只有他想说的话是重要的。”我进而向他们解释，推断他人的想法和对他人行为的观察是两码事。随后，第四位老师大胆地说：“他总是想成为人前的焦点。”当我指出这也是推断时，两位老师不约而同地说道：“你的问题太难回答了！” 接着，我们一起拟了份清单，明确列出校长有哪些具体行为令他们感到不满，并确保不掺杂评论。例如，在全体教师会议上，校长会讲述他的童年和战争经历，有时导致会议超时20分钟。我问老师们是否曾经和校长沟通过他们的不满，他们说曾经试过，但都用具有评论意味的言辞向校长提出批评，而从未提及任何具体行为，例如校长在会议中讲述自己的故事。最后，老师们同意在与校长会谈时将这一点提出来。 会谈刚一开始，我便目睹了老师们所描述的情景。不论讨论的主题是什么，校长都会插话说：“想当年……”接着开始讲述他的童年或战争经历。我等着老师们表达他们的不满。然而，他们并没有运用非暴力沟通的方式，而是无声的抗议。有的人开始翻白眼，有的人故意打着哈欠，还有个人一直盯着手表。 直到我按捺不住问他们：“没有人有话要说吗？”迎来的是一阵令人尴尬的沉默。接着，之前会谈中率先发言的那位老师鼓起勇气，直视着校长，然后说出：“艾德，你真是个大嘴巴！” 就像这个故事所展现的，从我们的旧习惯中挣脱出来，并有能力熟练地区分观察与评论并不容易。最终，老师们终于可以明明白白地告诉校长，他们对他的哪些行为感到不满。校长认真地听完后郑重地说：“为什么从没有人告诉我呢？”他承认他有讲故事的习惯，接着就开始说与这个习惯有关的故事了！我见状打断了他的话，婉转地提出他在重蹈覆辙。会议最后，我们商量了一些办法，以后当老师们不想听校长回忆往事时，就用温和的方式提醒他。 区分观察和评论 在以下列表中，我举例说明如何从混杂着评论的句子中区分出观察。 续表 注意：总是、永远、从来、每次之类的词语在以下用法中表达的是观察： ·每次我看到杰克打电话，他都至少打半小时。<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "nodes = retriever_chunk.retrieve(\"在日常交流中，我们如何区分客观的观察和主观的评价？\")\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_chunk = RetrieverQueryEngine.from_args(retriever_chunk, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: 在日常交流中，我们如何区分客观的观察和主观的评价？\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: df746b85-3568-48b2-9961-5bea0277c3f6\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id df746b85-3568-48b2-9961-5bea0277c3f6: 在日常交流中，我们如何区分客观的观察和主观的评价？\n",
      "\u001b[0m在日常交流中，区分客观观察和主观评价的关键在于是否包含个人判断或推测。客观观察应聚焦于具体、可验证的事实，而主观评价则往往带有个人观点或情感色彩。\n",
      "\n",
      "例如，说\"会议超时20分钟\"是观察，因为它陈述了可量化的事实；而说\"他话太多\"则是评价，因为包含了说话者对行为的主观判断。同样，\"他讲述了童年经历\"是观察，而\"他想成为焦点\"是评价。\n",
      "\n",
      "要有效区分两者，可以：\n",
      "1. 避免使用绝对化词汇（如总是、从不）\n",
      "2. 描述具体行为而非概括性格\n",
      "3. 确保陈述的内容可以被摄像机记录\n",
      "4. 将时间、地点等具体细节纳入描述\n",
      "\n",
      "这种区分需要练习，因为人们往往习惯于混合表达观察与评价。通过有意识地训练，我们能够更清晰地进行事实性沟通，减少因评价性语言引发的误解或冲突。\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_chunk.query(\n",
    "    \"在日常交流中，我们如何区分客观的观察和主观的评价？\"\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "2753\n"
     ]
    }
   ],
   "source": [
    "print(len(base_nodes))\n",
    "print(len(all_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nodes = base_nodes[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:19<00:00,  8.79s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = generate_question_context_pairs(test_nodes, llm=llm)\n",
    "eval_dataset.save_json(\"./feibaoli_eval_dataset50.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成答案测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llama_index.core.evaluation import RetrieverEvaluator, get_retrieval_results_df\n",
    "\n",
    "# set vector retriever similarity top k to higher\n",
    "top_k = 10\n",
    "\n",
    "\n",
    "def display_results(names, results_arr):\n",
    "    \"\"\"Display results from evaluate.\"\"\"\n",
    "\n",
    "    hit_rates = []\n",
    "    mrrs = []\n",
    "    for name, eval_results in zip(names, results_arr):\n",
    "        metric_dicts = []\n",
    "        for eval_result in eval_results:\n",
    "            metric_dict = eval_result.metric_vals_dict\n",
    "            metric_dicts.append(metric_dict)\n",
    "        results_df = pd.DataFrame(metric_dicts)\n",
    "\n",
    "        hit_rate = results_df[\"hit_rate\"].mean()\n",
    "        mrr = results_df[\"mrr\"].mean()\n",
    "        hit_rates.append(hit_rate)\n",
    "        mrrs.append(mrr)\n",
    "\n",
    "    final_df = pd.DataFrame({\"retrievers\": names, \"hit_rate\": hit_rates, \"mrr\": mrrs})\n",
    "    display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 35.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# base\n",
    "base_retriever = base_index.as_retriever(similarity_top_k=top_k)\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=base_retriever\n",
    ")\n",
    "\n",
    "# 异步并行评估需要qdrant aclient\n",
    "results_base = await retriever_evaluator.aevaluate_dataset(\n",
    "    eval_dataset, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk\n",
    "vector_retriever_chunk = vector_chunk_index.as_retriever(similarity_top_k=top_k)\n",
    "retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")\n",
    "retriever_evaluator_chunk = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=retriever_chunk\n",
    ")\n",
    "\n",
    "results_chunk = await retriever_evaluator_chunk.aevaluate_dataset(\n",
    "    eval_dataset, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base Retriever</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.099544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retriever (Chunk References)</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.444119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     retrievers  hit_rate       mrr\n",
       "0                Base Retriever      0.29  0.099544\n",
       "1  Retriever (Chunk References)      0.60  0.444119"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_results_df = get_retrieval_results_df(\n",
    "    [\"Base Retriever\", \"Retriever (Chunk References)\"],\n",
    "    [results_base, results_chunk],\n",
    ")\n",
    "display(full_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试中文问答题目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [09:15<00:00, 11.10s/it]\n"
     ]
    }
   ],
   "source": [
    "from readai.components.prompts import QA_GENERATE_PROMPT_TMPL_ZH\n",
    "\n",
    "eval_dataset_zh = generate_question_context_pairs(\n",
    "    test_nodes, llm=llm, qa_generate_prompt_tmpl=QA_GENERATE_PROMPT_TMPL_ZH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重写方法，保存中文内容\n",
    "import json\n",
    "\n",
    "path = \"./feibaoli_eval_dataset50_zh.json\"\n",
    "with open(path, \"w\") as f:\n",
    "    json.dump(eval_dataset_zh.model_dump(), f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 33.85it/s]\n"
     ]
    }
   ],
   "source": [
    "results_base_zh = await retriever_evaluator.aevaluate_dataset(\n",
    "    eval_dataset_zh, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_chunk_zh = await retriever_evaluator_chunk.aevaluate_dataset(\n",
    "    eval_dataset_zh, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base Retriever</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.093258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retriever (Chunk References)</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.549000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     retrievers  hit_rate       mrr\n",
       "0                Base Retriever      0.32  0.093258\n",
       "1  Retriever (Chunk References)      0.62  0.549000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_results_df_zh = get_retrieval_results_df(\n",
    "    [\"Base Retriever\", \"Retriever (Chunk References)\"],\n",
    "    [results_base_zh, results_chunk_zh],\n",
    ")\n",
    "display(full_results_df_zh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readai-vv5wOT8E-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
