{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import (\n",
    "    UnstructuredMarkdownLoader,\n",
    ")\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "from llama_index.core.schema import BaseNode, Document, IndexNode, NodeWithScore\n",
    "\n",
    "from readai.components.retrievers import BM25Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 获取项目根目录路径\n",
    "project_root = Path(os.getenv(\"PROJECT_ROOT\"))\n",
    "test_data_path = project_root / \"readai/tests/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点数量: 41\n"
     ]
    }
   ],
   "source": [
    "book_name = \"comunication_cleaned.md\"\n",
    "book_path = test_data_path / book_name\n",
    "# 使用unstructured的markdownloader加载\n",
    "loader = UnstructuredMarkdownLoader(book_path, mode=\"elements\")\n",
    "documents = loader.load()\n",
    "# 查看节点数量\n",
    "print(f\"节点数量: {len(documents)}\")\n",
    "# 遍历documents,重构metadata，只保留category，filename这两个属性\n",
    "for doc in documents:\n",
    "    category = doc.metadata[\"category\"]\n",
    "    filename = doc.metadata[\"filename\"]\n",
    "    doc.metadata = {\n",
    "        \"category\": category,\n",
    "        \"filename\": filename,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamindex_docs = [\n",
    "    Document(\n",
    "        text=doc.page_content,\n",
    "        metadata=doc.metadata,\n",
    "        metadata_seperator=\"::\",\n",
    "        metadata_template=\"{key}=>{value}\",\n",
    "        text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n",
    "    )\n",
    "    for doc in documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(llamindex_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11084a82ae034937824f6775e1ed8bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "马歇尔·卢森堡博士发现了一种沟通方式，依照它来谈话和聆听，能使人们情意相通，和谐相处，这就是“非暴力沟通”。 做为一个遵纪守法的好人，也许我们从来没有把谈话和“暴力”扯上关系。不过如果稍微留意一下现实生活中的谈话方式，并且用心体会各种谈话方式给我们的不同感受，我们一定会发现，有些话确实伤人！言语上的指责、嘲讽、否定、说教以及任意打断、拒不回应、随意出口的评价和结论给我们带来的情感和精神上的创伤甚至比肉体的伤害更加令人痛苦。这些无心或有意的语言暴力让人与人变得冷漠、隔膜、敌视。 非暴力沟通能够： ● 疗愈内心深处的隐秘伤痛； ● 超越个人心智和情感的局限性； ● 突破那些引发愤怒、沮丧、焦虑等负面情绪的思维方式； ● 用不带伤害的方式化解人际间的冲突； ● 学会建立和谐的生命体验。 图书在版编目(CIP)数据 非暴力沟通／（美）马歇尔·卢森堡（Marshall B.Rosenberg）著；刘轶译.-2版（修订本）-北京：华夏出版社有限公司，2021.5 书名原文：Nonviolent Communication ISBN 978-7-5222-0051-4 Ⅰ.①非⋯Ⅱ.①马⋯②刘⋯Ⅲ.①心理交往-通俗读物Ⅳ.①C912.11-49 中国版本图书馆CIP数据核字（2021）第006542号 Translated from the book Nonviolent Communication:A Language of Life 3rd Edition,ISBN 13/10:9781892005281/189200528X by Marshall B.Rosenberg. Copyright ? Fall 2015 Puddle Dancer Press,published by Puddle Dancer Press. All rights reserved. Used with permission. For further information about Nonviolent Communication(TM) please visit the Center for Nonviolent Communication on the Web at:www.cnvc.org.\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "node_parser = SimpleNodeParser.from_defaults(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=50,\n",
    "    separator=\"\\n\\n\",\n",
    "    secondary_chunking_regex=\"[^,.;。？！]+[,.;。？！]?\",\n",
    ")\n",
    "hybrid_nodes = node_parser.get_nodes_from_documents(llamindex_docs, show_progress=True)\n",
    "print(hybrid_nodes[0].text)\n",
    "print(len(hybrid_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.deepseek import DeepSeek\n",
    "\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "model_name = os.getenv(\"DEEPSEEK_MODEL\")\n",
    "embed_model = OllamaEmbedding(\n",
    "    model_name=\"quentinz/bge-large-zh-v1.5\", base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "# 设置 LLM\n",
    "llm = DeepSeek(model=model_name, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices import load_index_from_storage\n",
    "from llama_index.core.indices.vector_store.base import VectorStoreIndex\n",
    "from llama_index.core.storage.storage_context import StorageContext\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from qdrant_client import AsyncQdrantClient, QdrantClient\n",
    "\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "aclient = AsyncQdrantClient(url=\"http://localhost:6333\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = \"qdrant_nodes_test\"\n",
    "client.collection_exists(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 构建索引并持久化\n",
    "# 创建 Qdrant 向量存储（指定集合名称，可任选）\n",
    "qdrant_vs = QdrantVectorStore(\n",
    "    collection_name=collection_name, client=client, aclient=aclient\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core.storage.index_store import SimpleIndexStore\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(hybrid_nodes)\n",
    "index_store = SimpleIndexStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c0c6e9e38b4a0d9e729fdf1a0395ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 准备文档数据或节点\n",
    "# 使用 Qdrant 向量存储构建 VectorStoreIndex\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=qdrant_vs, docstore=docstore, index_store=index_store\n",
    ")\n",
    "index = VectorStoreIndex(\n",
    "    nodes=hybrid_nodes,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    "    llm=llm,\n",
    "    show_progress=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_dir = test_data_path / collection_name\n",
    "# index.storage_context.persist(persist_dir=persist_dir)\n",
    "storage_context.persist(persist_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "print(len(storage_context.docstore.docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从持久化目录加载 DocStore 和 IndexStorre\n",
    "persist_dir = test_data_path / collection_name\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    persist_dir=persist_dir, vector_store=qdrant_vs\n",
    ")\n",
    "loaded_index = load_index_from_storage(\n",
    "    storage_context, llm=llm, embed_model=embed_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = loaded_index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 82cd620b-d0f1-46a7-8690-57bbbe8da0e7<br>**Similarity:** 0.60743076<br>**Text:** 去观察，就像信仰一样重要。 ——弗雷德里克·布希纳（Frederick Buechner） 我欣然接受你告诉我， 我做了什么或者我未做什么。 我也欣然接受你的评论， 但请不要将两者混淆。 如果你...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b98f7cc1-d6cf-44bc-9284-4d8ee291a908<br>**Similarity:** 0.59909445<br>**Text:** 当我指出这一点后，另一位老师响应道：“我知道他的意思了。校长的话太多！”这仍不是一个清晰的观察，而是对校长说多少话的评论。随后，第三位老师说：“他认为只有他想说的话是重要的。”我进而向他们解释，...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 0af9b440-d87f-4f0d-9940-f7a6e343bd93<br>**Similarity:** 0.5780674<br>**Text:** 但他不是个懒汉。 请在说我胡言乱语之前， 想一想，他真的是个懒汉，还是 他的行为被我们贴上了“懒惰”的标签？ 我从未见过什么傻孩子； 这个孩子有时做的事， 我不理解或始料不及， 这个孩子的看法与...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = retriever.retrieve(\"在日常交流中，我们如何区分客观的观察和主观的评价？\")\n",
    "for node in nodes:\n",
    "    display_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试查询\n",
    "query_engine = loaded_index.as_query_engine(llm=llm, embed_model=embed_model)\n",
    "response = query_engine.query(\"在日常交流中，我们如何区分客观的观察和主观的评价？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-index-storage-docstore-redis\n",
    "# %pip install llama-index-storage-index-store-redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=RedisDocumentStore.from_host_and_port(\n",
    "        host=REDIS_HOST, port=REDIS_PORT, namespace=\"llama_index\"\n",
    "    ),\n",
    "    index_store=RedisIndexStore.from_host_and_port(\n",
    "        host=REDIS_HOST, port=REDIS_PORT, namespace=\"llama_index\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "storage_context.docstore.add_documents(nodes)\n",
    "len(storage_context.docstore.docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.docstore.redis import RedisDocumentStore\n",
    "from llama_index.storage.index_store.redis import RedisIndexStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# create (or load) docstore and add nodes\n",
    "index_store = RedisIndexStore.from_host_and_port(\n",
    "    host=\"127.0.0.1\", port=\"6379\", namespace=\"llama_index\"\n",
    ")\n",
    "\n",
    "# create storage context\n",
    "storage_context = StorageContext.from_defaults(index_store=index_store)\n",
    "\n",
    "# build index\n",
    "index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "\n",
    "# or alternatively, load index\n",
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "index = load_index_from_storage(storage_context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readai-vv5wOT8E-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
