{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "from langchain_community.document_loaders import (\n",
    "    UnstructuredEPubLoader,\n",
    "    UnstructuredMarkdownLoader,\n",
    ")\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.indices.vector_store.base import VectorStoreIndex\n",
    "from llama_index.core.node_parser import (\n",
    "    HierarchicalNodeParser,\n",
    "    get_leaf_nodes,\n",
    "    get_root_nodes,\n",
    ")\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.core.storage import StorageContext\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.deepseek import DeepSeek\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "from readai.components.custom.text_splitters.chinese_text_splitter import (\n",
    "    ChineseRecursiveTextSplitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置MLflow\n",
    "try:\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5001\")\n",
    "    mlflow.get_tracking_uri()\n",
    "    mlflow.set_experiment(\"LlamaIndex-RAG\")\n",
    "    mlflow.llama_index.autolog()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# 设置模型\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "model_name = os.getenv(\"DEEPSEEK_MODEL\")\n",
    "Settings.llm = DeepSeek(model=model_name, api_key=api_key)\n",
    "Settings.embed_model = OllamaEmbedding(\n",
    "    model_name=\"quentinz/bge-large-zh-v1.5\", base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "# 第一步：使用 UnstructuredEPubLoader 加载 EPUB 文档\n",
    "test_data_path = Path(\n",
    "    \"/Users/pegasus/workplace/mygits/readest-ai/readai-backend/readai/tests/data\"\n",
    ")\n",
    "book_name = \"非暴力沟通.epub\"\n",
    "book_path = test_data_path / book_name\n",
    "loader = UnstructuredEPubLoader(book_path, mode=\"elements\", strategy=\"hi_res\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 使用中文文本分割器\n",
    "text_splitter = ChineseRecursiveTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# 转换为llamaindex需要的documents对象\n",
    "llama_documents = [\n",
    "    Document(text=doc.page_content, metadata=doc.metadata) for doc in split_documents\n",
    "]\n",
    "\n",
    "# 创建层级解析器\n",
    "parser = HierarchicalNodeParser.from_defaults(chunk_sizes=[2048, 1024])\n",
    "book_nodes = parser.get_nodes_from_documents(llama_documents)\n",
    "leaf_nodes = get_leaf_nodes(book_nodes)\n",
    "root_nodes = get_root_nodes(book_nodes)\n",
    "\n",
    "print(f\"切分后节点总数量: {len(leaf_nodes)}\")\n",
    "print(f\"根节点数量: {len(root_nodes)}\")\n",
    "\n",
    "# 初始化Qdrant客户端\n",
    "qdrant_client = QdrantClient(\n",
    "    host=\"localhost\", port=6333\n",
    ")  # 使用内存存储，也可以指定本地路径\n",
    "vector_store = QdrantVectorStore(client=qdrant_client, collection_name=\"book_test0331\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建文档存储\n",
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(book_nodes)\n",
    "\n",
    "# 创建存储上下文\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=docstore, vector_store=vector_store\n",
    ")\n",
    "\n",
    "# 创建基础索引\n",
    "base_index = VectorStoreIndex(nodes=leaf_nodes, storage_context=storage_context)\n",
    "\n",
    "# 创建基础检索器\n",
    "base_retriever = base_index.as_retriever(similarity_top_k=6)\n",
    "\n",
    "# 创建AutoMergingRetriever\n",
    "from llama_index.core.retrievers import AutoMergingRetriever\n",
    "\n",
    "retriever = AutoMergingRetriever(\n",
    "    base_retriever, storage_context, verbose=True, simple_ratio_thresh=0.6\n",
    ")\n",
    "\n",
    "# 创建查询引擎\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever)\n",
    "\n",
    "# 执行查询\n",
    "query = \"非暴力沟通的第一个要素是什么？\"\n",
    "response = query_engine.query(query)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readai-vv5wOT8E-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
